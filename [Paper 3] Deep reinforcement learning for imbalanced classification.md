# Deep reinforcement learning for imbalanced classification
## **개요**
- 기존의 분류 알고리즘은 데이터 분포가 불균형한 경우 효과적이지 않음.  
- 이 문제를 해결하기 위해 심층 강화 학습을 기반으로 한 일반적인 불균형 분류 모델을 제안함. 이 모델은 분류문제를 순차적인 의사결정과정으로 공식화하고 심층 Q-학습네트워크로 해결함.  
- 모델의 에이전트는 각 시간단계에서 하나의 샘플에 대해 분류작업을 수행하고 환경은 분류작업을 평가하고 에이전트에 보상을 함. 소수 클래스 샘플의 보상이 더 크므로 에이전트는 소수 클래스에 더 민감함. 에이전트는 최종적으로 특정 보상 기능과 유사한 시뮬레이션 환경에 따라 불균형 데이터에서 최적의 분류 정책을 찾아냄.  
- 실험 결과, 이 논문에서 제안한 모델이 다른 불균형 분류 알고리즘보다 더 나은 성능을 보이며 더 많은 샘플을 식별하는 것으로 나타남.  

<br/></br>
## **1. 소개**  
불균형 데이터 분류는 기계학습분야에서 광범위하게 연구되었었다. 비정상 감지, 징병 진단, 위험행동 인식 등과 같은 일부 실제 분류연구에서도 데이터 분포가 매우 왜곡되어있다. 한 클래스의 사례가 다른 클래스보다 1000배 적은 경우가 예이다. 대부분의 기계학습 알고리즘은 균형잡힌 훈련 데이터 세트에 적합하다. 이런 불균형 데이터로 훈련한 모델은 종종 다수의 클래스에 대해 좋은 인식결과를 제공하고, 소수의 클래스에 대해서는 왜곡하는 결과를 제공한다. 소수 클래스의 인스턴스는 빈도가 낮아 감지가 어렵기 때문이다. 이러한 문제를 해결하는 방법은 두가지로 나뉜다. 

    1) 다른 유형의 데이터 조작 기술로 표현되는 훈련 데이터를 다시 샘플링하여 클래스 분포의 균형을 맞추기 위해 인스턴스 모음 수정  
    2) 기존 학습자를 수정하여 다수 클래스에 대한 편향을 완화하며, 소수 클래스에 더 높은 오분류 비용을 할당
    
그러나 빅데이터의 급속한 발전으로 인해 불균형 비율이 높은 복잡한 데이터가 대량으로 생성되고 있기 때문에 기존의 방법은 점점 더 복잡해지는 데이터를 처리하는데 부적절하다. 하여 새로운 딥러닝 접근 방식이 점점 대중화되고 있다.  
심층 강화 학습은 소수 집단에게 더 높은 보상을 제공함으로써 소수 집단에 더 많은 관심을 기울일 수 있다. 이 논문에서는 DQN기반 모델을 제안하는데, 여기서 불균형 분류 문제는 순차적인 의사결정 과정으로 분해될 수 있는 추측 게임으로 간주된다. 각 시간단계에서 에이전트는 학습 샘플로 표시되는 환경상태를 수신한 다음 지침에 따라 분류 작업을 수행한다. 에이전트가 올바른 분류작업을 수행하면 긍정적인 보상이 주어지고, 그렇지 않으면 부정적인 보상이 주어진다. 소수 계급의 보상은 다수 계급의 보상보다 높다. 에이전트의 목표는 순차적인 의사결정과정에서 최대한 많은 누적 보상을 획득하는 것이다. 즉, 가능한 샘플을 정확하게 인식하는 것이다.  
연구 과정은 다음과 같다.

    1) 분류문제를 순차적인 의사결정과정으로 공식화하고 불균형분류를 위한 심층 강화 학습 프레임 워크를 제안
    2) 시뮬레이션 환경 구축, 에이전트와 환경간의 상호작용규칙 정의, 특정 보상 기능 설계를 포함하는 DQN기반 불균형 분류 모델 설계 및 구현
    3) 실험을 통해 모델의 성능을 연구하고 다른 불균형 데이터 학습방법과 비교
    
<br/></br>
## **2. 관련된 정보**  
불균형 데이터 분류에 대한 이전 작업과 심층 강화 학습을 통한 분류 방법을 소개한다.  

### **1. 불균형 데이터 분류**  
    - SMOTE : 오버샘플링 방법으로, 인접한 소수 샘플 간의 선형관계를 통해 새 샘플을 생성함  
    - NearMiss : 최근접이웃 알고리즘을 기반으로 하는 언더 샘플 방법  
오버샘플링은 잠재적으로 과적합으로 이어질 수 있고, 언더샘플링은 대다수 클래스에 대한 중요한 정보를 잃을 수 있다.  

알고리즘은 비용에 민감한 학습, 앙상블 학습, 결정 임계값 조정을 포함한 기존 알고리즘을 개선하여 소수 클래스의 중요성을 높이는 것을 목표로 한다.  

    - 비용에 민감한 학습 방법 : 소수클래스의 오분류 비용이 다수클래스보다 높은 손실 함수를 수정하여 여러 클래스에 다양한 오분류비용을 할당
    - 앙상블 기반 학습 방법 : 여러 개별 하위 분류자를 훈련한 다음 투표 또는 결합을 통해 더 나은 결과를 얻는 것
    - 임계값 조정 방법 : 원래 분균형 데이터에서 분류기를 훈련 시키고 테스트때 결정 임계값을 변경  

최근 불균형 데이터 분류를 위해 다양한 딥러닝 기반 방법이 제안되었다.

    1) 다수 클래스와 소수 클래스 모두에서 분류 오류를 동일하게 캡처할 수 있는 심층 신경망에 새로운 손실함수를 제안
    2) 클러스터/클래스 간 차이를 유지하여 불균형데이터의 보다 차별적인 특징을 학습하는 방법을 연구
    3) 컨볼루션 신경망에 대한 각 미니배치의 훈련 데이터가 균형을 이루도록 보장하는 부트 스트래핑 샘플링 알고리즘 사용
    4) 소수 클래스에서 샘플을 채굴하고 클래스 정류 손실기능을 사용한 일괄 최적화로 알고리즘 개선 ← 네트워크 매개변수와 클래스에 민감한 비용을 함께 최적화 가능
    
### **2. 분류 문제에 대한 강화학습**  
심층 강화학습은 분류자가 유리한 기능을 학습하거나 잡음이 있는 데이터에서 고품질 인스턴스를 선택하는데 도움이 될 수 있다. 에이전트는 최적의 분류정책을 학습하기 위해 환경과 상호작용한다. 그러나 에이전트와 환경 간의 복잡한 시뮬레이션으로 인해 시간이 매우 복잡해진다. 하여 이 논문에서는 2개의 학습 모델을 제안하였다.

1. 잡음이 많은 텍스트 데이터에서 관계분류를 학습하기 위해 심층 강화 학습 기반 모델   
모델은 인스턴스 선택기와 관계형 분류기로 구분된다. 인스턴스 선택기는 에이전트의 안내에 따라 노이즈가 많은 데이터에서 고품질 문장을 선택하고, 관계형 분류기는 선택된 깨끗한 데이터에서 더 나은 성능을 학습하고 지연된 보상을 인스턴스 선택자에게 피드백한다. 유리한 기능은 분류기를 통해 개선하고, 더 나은 분류자는 더 높은 보상을 피드백하여 에이전트가 더 유리한 기능을 선택하도록 하는 것이다.  
2. 특정 보상함수와 마르코프 프로세스의 정의가 명확하게 공식화된 시계열 데이터 분류를 위한 심층 강화 학습 프레임 워크  

강화학습을 통한 불균형 데이터 분류는 매우 제한적이었다. 강화학습을 이용하여 최상/하위 분류자를 선택하는 앙상블 가치지기 기법을 제시하였으나 이 방법은 하위 분류자가 많을때 비효율적이었기 때문에 기존의 소규모 데이터 세트에만 적합했다. 심층 강화 학습과 분류기를 통합하면 많은 응용 분야에서 유망한 결과가 나타났지만 불균형 분류에 적용될 때 강화 학습의 성능을 탐색하는 것은 고무적이었다.  

<br/></br>
## **3. 방법론**  
### **1. 불균형 분류 Markov 결정 프로세스**  
### **2. 불균형 데이터 분류에 대한 보상 기능**  
### **3. DQN기반 불균형 분류 알고리즘**  

<br/></br>
## **4. 실험**  
DQNimb모델을 다른 불균형 학습 방법과 비교하고, 다른 수준의 불균형 비율로 DQNimb모델을 평가하기 위해 실증적 연구를 수행하였다. 공정하고 포괄적인 비교를 위해 Friedman테스트를 수행하였고, DQNimb모델은 다른 모델보다 훨씬 뛰어난 성능을 보여주었다.  

### **1. 비교방법**  
데이터 수준과 알고리즘 수준에서 7개의 불균형 학습 방법을 비교하였다. 교차 엔트로피 손실함수로 훈련된 심층 신경망이 실험의 기준선으로 사용되었다.  비교 방법은 다음과 같다.  

    - DNN : 교차 엔트로피 손실함수를 사용하여 심층 신경망을 훈련시키는 방법  
    - ROS : 소수 클래스를 오버샘플링하여 데이터 세트를 임의 복제하는 균형잡힌 빌드를 위한 리샘플링 방법   
    - RUS : 과반수 클래스를 언더샘플링하여 데이터 세트에서 무작위 샘플 제거하는 균형잡힌 빌드를 위한 리샘플링 방법   
    - MFE : 불균형 데이터 세트에서 심층 신경망의 평균 오류 손실 함수를 사용하는 분류 성능 향상 방법  
    - CSM :   
    - DTA : 불균형 데이터에서 클래스 사전을 통합하여 테스트 시간에 모델 결정 임계값을 조정하는 심층 신경망 훈련 방법  
    - FL : 초점 손실을 감소시켜 잘 분류된 예제에 할당하는 표준 교차 엔트로피를 재구성하는 방법  
    - CRL : 소수 클래스에 대한 하드 샘플의 배치 방식 마이닝을 사용하고, 소수 클래스 증분 정류에 대한 클래스 정류 손실을 공식화 하는 방법  
    
DNN은 불균형 학습 접근법의 기본 모델로 사용되었다. ROS와 RUS는 소수클래스를 오버샘플링하거나 다수클래스를 언더샘플링한 데이터를 다시 샘플링하여 DNN을 분류 모델로 사용하였다. CSM은 비용을 클래스 빈도로 사용하는 여러 클래스에 다양한 오분류 비용을 할당하여 DNN모델을 훈련하였다. DTA는 DNN모델을 훈련시키고, 테스트때 모델 결정 임계값을 조정하였다. MFE와 FL는 DNN모델의 교차엔트로피 손실을 다른 방식으로 재구성하고, CRL은 소수 클래스에 대한 하드 샘플 마이닝을 수행하였다. DNN의 네트워크와 파라미터는 위 방법들에서 모두 공일하게 사용되었다.  

### **2. 평가지표**  
불균형 데이터 세트의 분류성능을 보다 합리적으로 평가하기 위해 G-mean 및 F-measure을 사용한다. G-mean은 재현율과 특이성의 기하학적 평균이고, F-measure은 재현율과 정밀도의 기하학적 평균을 나타낸다. G-mean과 F-measure 점수가 높을수록 알고리즘 성능이 향상된다. G-mean과 F-measure의 공식은 다음과 같다.  
![b](https://user-images.githubusercontent.com/59431387/104848723-a3b4d300-5929-11eb-8299-e755a40545b5.PNG)  


### **3. 데이터 세트**  
이 논문에서는 주로 심층 강화 학습을 통한 이진 불균형 분류 문제를 연구한다. 실험에 사용된 데이터 세트는 IMDB, Cifar-10, Mnist, Fashion-Mnist이다.  
![a](https://user-images.githubusercontent.com/59431387/104848545-cdb9c580-5928-11eb-8bcf-9319e334a8e7.PNG)   

    1. IMDB : 긍정/부정으로 분류된 50000개의 영화리뷰가 포함된 텍스트 데이터 세트  
            - 리뷰는 사전처리 되었으며, 각 리뷰는 일련의 단어 색인으로 인코딩됨.  
            - 클래스의 train와 test는 각 12500,12500개이다.  
            - 긍정적인 리뷰는 실험에서 긍정적인 클래스로 간주됨.  
    2. Mnist : 이미지 데이터 세트  
            - 28x28스케일의 이미지  
            - 10개의 클래스  
            - 클래스의 train과 test는 각 6000,1000개이다.  
            - 실험에서 라벨2가 있는 이미지는 긍정클래스, 나머지 이미지는 부정클래스로 지정함.  
    3. Fashion-Mnist   
            - 10개 클래스  
            - 총 70000개의 패션 제품에 대한 28개의 회색조 이미지 세트  
            - 각 클래스의 train과 test는 각 6000,1000개이다.  
            - 첫번째 0과 2로 표시된 이미지를 긍정클래스, 1과 3으로 표시된 이미지를 부정클래스로 선택  
              두번째 4~6로 표시된 이미지를 긍정클래스, 7~9로 표시된 이미지를 부정클래스로 선택  
    4. Cifar-10 : Fashion-Mnist보다 더 복잡한 이미지 데이터 세트  
            - 10가지 종류의 자연물이 있는 32x32컬러이미지  
            - 클래스의 train과 test는 각 5000,1000개이다.  
            - 서로 다른 두개의 시뮬레이션 된 데이터 세트가 있음  
            - 1로 표시된 이미지를 긍정클래스, 3~6으로 표시된 이미지를 부정클래스로 간주함.  
            
### **4. 네트워크 구조**  
모델은 심층신경망을 이용하여 불균형 및 고차원데이터세트에서 특징을 표현하는 것을 학습한다. 비교 알고리즘의 경우, 텍스트데이터 세트에 사용되는 네트워크 아키텍처는 임베딩 계층, LSTM계층, 완전 연결 계층 2개, 소프트맥스 출력계층이 있다.  
![c](https://user-images.githubusercontent.com/59431387/104849581-c648eb00-592d-11eb-9472-abfb96066da0.PNG)  
이미지 분류에 사용되는 네트워크 아키텍처에는 2개의 컨볼루션 계층, 2개의 완전연결 계층 및 소프트맥스 출력 계층이 있다.  
![d](https://user-images.githubusercontent.com/59431387/104849609-fa241080-592d-11eb-8dfe-e5c3ef162c2b.PNG)  
우리 모델의 경우 Q-네트워크 아키텍처는 비교 알고리즘과 유사하지만 최종 소프트맥스 출력 레이어는 확장할 필요가 없기 때문에 제거된다.  

### **5. 매개 변수 설정**  
DQNimb모델에서 ε-탐사, 탐사확률에 탐욕스러운 정책이 사용된다. ε 1.0에서 0.01까지 선형으로 감쇠된다. 대상 네트워크 업데이트 요소는 η0.05이다. 경험 재생 메모리의 크기는 50000이고, 에이전트와 환경 간의 상호작용은 약 120000단계이다. 즉각적인 보상의 요인은 γ0.01이다. Adam알고리즘은 매개변수를 최적화하는데 사용된다. Q-네트워크의 학습률은 0.00025이다. 다른 알고리즘의 경우 DNN은 기본분류기로 사용되며 최적화 프로그램은 Adam, 학습률 0.0005, 배치크기는 64이다. 학습데이터의 10%샘플을 검증데이터로 무작위 추출하고, 조기중지기법을 사용한다. 심층 신경망 훈련 중 검증 손실을 모니터링한다.  

### **6. 실험결과**  
불균형데이터학습을 연구하기 전에 DQNimb모델을 균형데이터 세트의 지도딥러닝 모델인 DNN과 비교한다. 실험은 6개의 데이터 세트이다. 긍정샘플과 부정샘플의 수가 동일하므로 DQNimb의 네트워크 아키텍처의 보상기능은 동일한 보상/처벌을 할당한다. 공정성과 설득력있는 비교를 위해 DNN모델의 네트워크 아키텍처는 DQNimb모델의 Q-네트워크 아키텍처와 동일하다. DQNimb모델은 Markov프로세스에서 누적보상을 최대화하여 최적의 분류전략을 얻는 반면, DNN은 교차엔트로피 손실함수를최소화하여 최적의 네트워크 매개 변수를 얻는다. 두 모델 모두 실험결과에서 우수한 성능을 보여준다. DQNimb모델의 G-mean과 F-measure은 DNN모델보다 약간 우수하다.  
![e](https://user-images.githubusercontent.com/59431387/104850289-93085b00-5931-11eb-8118-9dab98cd2a14.PNG)
