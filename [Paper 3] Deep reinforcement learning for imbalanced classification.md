# Deep reinforcement learning for imbalanced classification
## **개요**
- 기존의 분류 알고리즘은 데이터 분포가 불균형한 경우 효과적이지 않음.  
- 이 문제를 해결하기 위해 심층 강화 학습을 기반으로 한 일반적인 불균형 분류 모델을 제안함. 이 모델은 분류문제를 순차적인 의사결정과정으로 공식화하고 심층 Q-학습네트워크로 해결함.  
- 모델의 에이전트는 각 시간단계에서 하나의 샘플에 대해 분류작업을 수행하고 환경은 분류작업을 평가하고 에이전트에 보상을 함. 소수 클래스 샘플의 보상이 더 크므로 에이전트는 소수 클래스에 더 민감함. 에이전트는 최종적으로 특정 보상 기능과 유사한 시뮬레이션 환경에 따라 불균형 데이터에서 최적의 분류 정책을 찾아냄.  
- 실험 결과, 이 논문에서 제안한 모델이 다른 불균형 분류 알고리즘보다 더 나은 성능을 보이며 더 많은 샘플을 식별하는 것으로 나타남.  

<br/></br>
## **1. 소개**
불균형 데이터 분류는 기계학습분야에서 광범위하게 연구되었었다. 비정상 감지, 징병 진단, 위험행동 인식 등과 같은 일부 실제 분류연구에서도 데이터 분포가 매우 왜곡되어있다. 한 클래스의 사례가 다른 클래스보다 1000배 적은 경우가 예이다. 대부분의 기계학습 알고리즘은 균형잡힌 훈련 데이터 세트에 적합하다. 이런 불균형 데이터로 훈련한 모델은 종종 다수의 클래스에 대해 좋은 인식결과를 제공하고, 소수의 클래스에 대해서는 왜곡하는 결과를 제공한다. 소수 클래스의 인스턴스는 빈도가 낮아 감지가 어렵기 때문이다. 이러한 문제를 해결하는 방법은 두가지로 나뉜다. 

    1) 다른 유형의 데이터 조작 기술로 표현되는 훈련 데이터를 다시 샘플링하여 클래스 분포의 균형을 맞추기 위해 인스턴스 모음 수정  
    2) 기존 학습자를 수정하여 다수 클래스에 대한 편향을 완화하며, 소수 클래스에 더 높은 오분류 비용을 할당
    
그러나 빅데이터의 급속한 발전으로 인해 불균형 비율이 높은 복잡한 데이터가 대량으로 생성되고 있기 때문에 기존의 방법은 점점 더 복잡해지는 데이터를 처리하는데 부적절하다. 하여 새로운 딥러닝 접근 방식이 점점 대중화되고 있다.  
심층 강화 학습은 소수 집단에게 더 높은 보상을 제공함으로써 소수 집단에 더 많은 관심을 기울일 수 있다. 이 논문에서는 DQN기반 모델을 제안하는데, 여기서 불균형 분류 문제는 순차적인 의사결정 과정으로 분해될 수 있는 추측 게임으로 간주된다. 각 시간단계에서 에이전트는 학습 샘플로 표시되는 환경상태를 수신한 다음 지침에 따라 분류 작업을 수행한다. 에이전트가 올바른 분류작업을 수행하면 긍정적인 보상이 주어지고, 그렇지 않으면 부정적인 보상이 주어진다. 소수 계급의 보상은 다수 계급의 보상보다 높다. 에이전트의 목표는 순차적인 의사결정과정에서 최대한 많은 누적 보상을 획득하는 것이다. 즉, 가능한 샘플을 정확하게 인식하는 것이다.  
연구 과정은 다음과 같다.

    1) 분류문제를 순차적인 의사결정과정으로 공식화하고 불균형분류를 위한 심층 강화 학습 프레임 워크를 제안
    2) 시뮬레이션 환경 구축, 에이전트와 환경간의 상호작용규칙 정의, 특정 보상 기능 설계를 포함하는 DQN기반 불균형 분류 모델 설계 및 구현
    3) 실험을 통해 모델의 성능을 연구하고 다른 불균형 데이터 학습방법과 비교
    
<br/></br>
## **2. ?**
불균형 데이터 분류에 대한 이전 작업과 심층 강화 학습을 통한 분류 방법을 소개한다.
### **1. 불균형 데이터 분류**
