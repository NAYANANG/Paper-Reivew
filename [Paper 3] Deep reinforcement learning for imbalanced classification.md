# Deep reinforcement learning for imbalanced classification
## **개요**
- 기존의 분류 알고리즘은 데이터 분포가 불균형한 경우 효과적이지 않음.  
- 이 문제를 해결하기 위해 심층 강화 학습을 기반으로 한 일반적인 불균형 분류 모델을 제안함. 이 모델은 분류문제를 순차적인 의사결정과정으로 공식화하고 심층 Q-학습네트워크로 해결함.  
- 모델의 에이전트는 각 시간단계에서 하나의 샘플에 대해 분류작업을 수행하고 환경은 분류작업을 평가하고 에이전트에 보상을 함. 소수 클래스 샘플의 보상이 더 크므로 에이전트는 소수 클래스에 더 민감함. 에이전트는 최종적으로 특정 보상 기능과 유사한 시뮬레이션 환경에 따라 불균형 데이터에서 최적의 분류 정책을 찾아냄.  
- 실험 결과, 이 논문에서 제안한 모델이 다른 불균형 분류 알고리즘보다 더 나은 성능을 보이며 더 많은 샘플을 식별하는 것으로 나타남.  

<br/></br>
## **1. 소개**  
불균형 데이터 분류는 기계학습분야에서 광범위하게 연구되었었다. 비정상 감지, 징병 진단, 위험행동 인식 등과 같은 일부 실제 분류연구에서도 데이터 분포가 매우 왜곡되어있다. 한 클래스의 사례가 다른 클래스보다 1000배 적은 경우가 예이다. 대부분의 기계학습 알고리즘은 균형잡힌 훈련 데이터 세트에 적합하다. 이런 불균형 데이터로 훈련한 모델은 종종 다수의 클래스에 대해 좋은 인식결과를 제공하고, 소수의 클래스에 대해서는 왜곡하는 결과를 제공한다. 소수 클래스의 인스턴스는 빈도가 낮아 감지가 어렵기 때문이다. 이러한 문제를 해결하는 방법은 두가지로 나뉜다. 

    1) 다른 유형의 데이터 조작 기술로 표현되는 훈련 데이터를 다시 샘플링하여 클래스 분포의 균형을 맞추기 위해 인스턴스 모음 수정  
    2) 기존 학습자를 수정하여 다수 클래스에 대한 편향을 완화하며, 소수 클래스에 더 높은 오분류 비용을 할당
    
그러나 빅데이터의 급속한 발전으로 인해 불균형 비율이 높은 복잡한 데이터가 대량으로 생성되고 있기 때문에 기존의 방법은 점점 더 복잡해지는 데이터를 처리하는데 부적절하다. 하여 새로운 딥러닝 접근 방식이 점점 대중화되고 있다.  
심층 강화 학습은 소수 집단에게 더 높은 보상을 제공함으로써 소수 집단에 더 많은 관심을 기울일 수 있다. 이 논문에서는 DQN기반 모델을 제안하는데, 여기서 불균형 분류 문제는 순차적인 의사결정 과정으로 분해될 수 있는 추측 게임으로 간주된다. 각 시간단계에서 에이전트는 학습 샘플로 표시되는 환경상태를 수신한 다음 지침에 따라 분류 작업을 수행한다. 에이전트가 올바른 분류작업을 수행하면 긍정적인 보상이 주어지고, 그렇지 않으면 부정적인 보상이 주어진다. 소수 계급의 보상은 다수 계급의 보상보다 높다. 에이전트의 목표는 순차적인 의사결정과정에서 최대한 많은 누적 보상을 획득하는 것이다. 즉, 가능한 샘플을 정확하게 인식하는 것이다.  
연구 과정은 다음과 같다.

    1) 분류문제를 순차적인 의사결정과정으로 공식화하고 불균형분류를 위한 심층 강화 학습 프레임 워크를 제안
    2) 시뮬레이션 환경 구축, 에이전트와 환경간의 상호작용규칙 정의, 특정 보상 기능 설계를 포함하는 DQN기반 불균형 분류 모델 설계 및 구현
    3) 실험을 통해 모델의 성능을 연구하고 다른 불균형 데이터 학습방법과 비교
    
<br/></br>
## **2. ?**  
불균형 데이터 분류에 대한 이전 작업과 심층 강화 학습을 통한 분류 방법을 소개한다.  

### **1. 불균형 데이터 분류**  
    - SMOTE : 오버샘플링 방법으로, 인접한 소수 샘플 간의 선형관계를 통해 새 샘플을 생성함  
    - NearMiss : 최근접이웃 알고리즘을 기반으로 하는 언더 샘플 방법  
오버샘플링은 잠재적으로 과적합으로 이어질 수 있고, 언더샘플링은 대다수 클래스에 대한 중요한 정보를 잃을 수 있다.  

알고리즘은 비용에 민감한 학습, 앙상블 학습, 결정 임계값 조정을 포함한 기존 알고리즘을 개선하여 소수 클래스의 중요성을 높이는 것을 목표로 한다.  

    - 비용에 민감한 학습 방법 : 소수클래스의 오분류 비용이 다수클래스보다 높은 손실 함수를 수정하여 여러 클래스에 다양한 오분류비용을 할당
    - 앙상블 기반 학습 방법 : 여러 개별 하위 분류자를 훈련한 다음 투표 또는 결합을 통해 더 나은 결과를 얻는 것
    - 임계값 조정 방법 : 원래 분균형 데이터에서 분류기를 훈련 시키고 테스트때 결정 임계값을 변경  

최근 불균형 데이터 분류를 위해 다양한 딥러닝 기반 방법이 제안되었다.

    1) 다수 클래스와 소수 클래스 모두에서 분류 오류를 동일하게 캡처할 수 있는 심층 신경망에 새로운 손실함수를 제안
    2) 클러스터/클래스 간 차이를 유지하여 불균형데이터의 보다 차별적인 특징을 학습하는 방법을 연구
    3) 컨볼루션 신경망에 대한 각 미니배치의 훈련 데이터가 균형을 이루도록 보장하는 부트 스트래핑 샘플링 알고리즘 사용
    4) 소수 클래스에서 샘플을 채굴하고 클래스 정류 손실기능을 사용한 일괄 최적화로 알고리즘 개선 ← 네트워크 매개변수와 클래스에 민감한 비용을 함께 최적화 가능
    
### **2. 분류 문제에 대한 강화학습**  
심층 강화학습은 분류자가 유리한 기능을 학습하거나 잡음이 있는 데이터에서 고품질 인스턴스를 선택하는데 도움이 될 수 있다. 에이전트는 최적의 분류정책을 학습하기 위해 환경과 상호작용한다. 그러나 에이전트와 환경 간의 복잡한 시뮬레이션으로 인해 시간이 매우 복잡해진다. 하여 이 논문에서는 2개의 학습 모델을 제안하였다.

1. 잡음이 많은 텍스트 데이터에서 관계분류를 학습하기 위해 심층 강화 학습 기반 모델   
모델은 인스턴스 선택기와 관계형 분류기로 구분된다. 인스턴스 선택기는 에이전트의 안내에 따라 노이즈가 많은 데이터에서 고품질 문장을 선택하고, 관계형 분류기는 선택된 깨끗한 데이터에서 더 나은 성능을 학습하고 지연된 보상을 인스턴스 선택자에게 피드백한다. 유리한 기능은 분류기를 통해 개선하고, 더 나은 분류자는 더 높은 보상을 피드백하여 에이전트가 더 유리한 기능을 선택하도록 하는 것이다.  
2. 특정 보상함수와 마르코프 프로세스의 정의가 명확하게 공식화된 시계열 데이터 분류를 위한 심층 강화 학습 프레임 워크  

강화학습을 통한 불균형 데이터 분류는 매우 제한적이었다. 강화학습을 이용하여 최상/하위 분류자를 선택하는 앙상블 가치지기 기법을 제시하였으나 이 방법은 하위 분류자가 많을때 비효율적이었기 때문에 기존의 소규모 데이터 세트에만 적합했다. 심층 강화 학습과 분류기를 통합하면 많은 응용 분야에서 유망한 결과가 나타났지만 불균형 분류에 적용될 때 강화 학습의 성능을 탐색하는 것은 고무적이었다.  

