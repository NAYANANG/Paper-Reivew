# Deep ConvLSTM with self-attention for human activity decoding using wearables
## **개요**
- 다중 센서 시계열 데이터의 시공간적인 특징을 파악하고, 자기주의 메커니즘을 활용하여 중요한 시점을 선택하고 학습하는 심층 신경 네트워크 아키텍처를 제안한다.  
- 6개의 데이터셋에서 서로 다른 데이터 샘플링을 적용하여 제안된 접근법의 유효성을 보여주며, 자기주의 메커니즘이 반복 네트워크와 컨볼루션 네트워크를 결합하여 심층 네트워크에 비해 성능을 크게 향상시켰음을 입증한다.  
- 제안된 접근법이 이전의 방법에 비해 통계적으로 유의미한 성능 향상을 제공함을 보여준다. 제안된 방법은 장기간에 걸쳐 여러 신체센서에서 인간의 활동을 더 잘 디코딩할 수 있다.

<br/></br>
## **1. 소개**
인간활동 디코딩은 건강 모니터링, 생활 상태 및 일일 활동을 포함한 인간 복지를 위한 새로운 응용 프로그램을 변화시켰다. 인간의 활동을 감지하기 위해 사용되는 가장 인기있는 방법은 컴퓨터 비전과 웨어러블 센서를 기반으로 한다.  
- 컴퓨터 비전 : 일반적으로 인간 활동을 추적하고 기록하는데 카메라가 사용 / 카메라를 다른 각도로 조정하고 카메라에서 획득한 이미지에 대한 딥러닝을 사용하여 인간활동을 디코딩하는 것이 어려움.
- 웨어러블 센서 : 필요에 따라 신체의 다른 부분에 배치될 수 있거나 피사체의 주머니에 넣을 수 있는 작은 마이크로 장치  

더욱이, 무선기술의 발전으로 휴대용 저전력 고효율 웨어러블 센서 장치 제작이 가능해지고 있다.  
- 웨어러블 센서 유닛 : 생화학적/이동 데이터를 추출하기 위한 입력데이터 센서, 수집된 데이터를 원격장치로 보내기 위한 신호 전송 장치, 관련 특징과 정보를 추출하기 위한 신호처리 및 데이터 분석 장치로 구성  

입력센서에서 추출된 신호는 노이즈가 많고 출력이 낮기 때문에 형상추출과 분류를 수행하기 전에 필터링과 증폭이 필요하다. 때문에 많은 연구자들은 서로 다른 신체 부위에 배치된 센서에서 생성된 시계열 데이터에서 수작업으로 만든 기능을 사용한다.수작업에는 통계기능(평균, 분산), Fourier변환과 같은 주파수 영역이 포함된다. 그러나 수작업으로 진행된 기능은 데이터에 크게 의존하며 애플리케이션 도메인 전체에서 일반화되지 않는다. 또한 시간이 많이 소요되며 종종 제한된 수의 기능만 특정 데이터 집합에서 생성하는 경우도 있다.   

수작업으로 진행된 기능은 지도기계학습 알고리즘으로 샘플을 분류하는데 사용된다. 최근의 접근 방식은 복잡한 데이터 구조에서 자동 특징 학습을 위한 딥러닝 접근법을 탐색하여 수작업으로 만들어진 특징의 한계를 극복한다. 이에 CNN이 많은 관심을 받았다.  
- CNN
    - 컨볼루션 연산을 사용하여 자체 내에서 특징을 추출하며 일반화 기능과 독립적임
    - 성능향상에도 불구하고 CNN은 계산 비용이 많이 들고 많은 수의 학습데이터를 필요로 함 → 그래픽 처리 능력, 데이터 확대 기법, 신경 네트워크 아키텍처의 발전으로 부분적으로 완화되었음
    - 센서데이터의 공간영역을 캡처하고 단순한 인간활동에 합리적인 성능을 제공하지만 웨어러블 센서 시계열 신호의 시간적 특성 분석이 필요한 복잡한 활동은 캡처 불가능  

- RNN
    - 시계열 데이터의 시간적 정보를 중요시할 수 있음
    - 웨어러블 센서의 활동인식에 사용
    - 의존적 입력 시퀀스를 처리하도록 특별히 설계된 특수한 유형의 신경 네트워크
    - (문제점) 훈련하기 어렵게 만든 경사로가 사라지거나 폭발함 → (해결방안) 서로 달느 시점 사이의 정보흐름을 위해 게이트를 추가하는 LSTM네트워크 출현

- LSTM
    - 자연어 처리에 많이 사용  
    
문헌의 여러 연구는 공간 도메인정보를 캡처하는 CNN과 임시 도메인정보를 위한 LSTM을 활용하여 CNN과 LSTM의 조합을 제안한다. CNN과 LSTM은 시공간 정보를 효과적으로 포착할 수 있지만 여러 구성요소가 함께 인간활동을 해독하는 의미를 형성할 수 있기 때문에 CNN과 LSTM조합에 의해 생성된 임베딩에서 특정 정보에 초점을 맞추고 이들을 결합할 필요가 있다. 이는 이전 연구에서 고려되지 않았으며, 매트릭스의 각 행이 문장의 다른 부분에 전달되도록 입력의 포함을 나타내기 위해 2D매트릭스를 형성하는 자기주의 메커니즘을 사용하여 수행될 수 있다.

<br/></br>
## **2. 센서 및 시점선택을 위한 모델 제안**
![model1](https://user-images.githubusercontent.com/59431387/103484740-844f7d80-4e34-11eb-8fa7-d1d9537e0605.PNG)
1) 임배딩 레이어 : 웨어러블 센서의 입력으로부터 임배딩을 학습하기 위한 다중 1차원 컨볼루션 필터로 구성  
2) CNN계층의 인코더 : 하나 이상의 LSTM레이어로 구성  
3) 주의 모듈 : 중요한 시점을 학습하기 위한 주의 계층으로 구성  
4) 하위 모듈 위에 SoftMax 분류계층을 추가  

- Embedding Layer  
       - Embedding layer를 추가하는 것은 1차원 공간 컨볼루션 연산을 사용하여 웨어러블 센서의 표현을 학습하는 것
- LSTM Encoder  
       - RNN인코더 아키텍처를 사용하여 시점간의 종속성을 포착
       - 인코더는 하나 이상의 LSTM레이어로 구성될 수 있음
- Self-Attention Layer  
       - CNN레이어와 LSTM유닛을 융합한 상황별 특징과 시간 역학을 모두 활용한 후, 입력 데이터 샘플에서 각 기능의 중요도인 가중치 계수를 학습하기 위해 자체 주의 계층을 사용함
       - 주의계층 : 상태 레이블을 결정하는데 도움이 되는 센서 시계열 데이터로부터 중요한 시점을 학습하는 것을 목표로 함
- SoftMax Layer  
- Learning  
       - 교차 엔트로피 비용 J는 제안된 모델을 훈련시키기 위해 최소화됨

<br/></br>
## **3. 실험 설정**
### **1. 데이터 세트 설명**
1. MHEACH  
  - 12명 피험자의 왼쪽 발목과 가슴, 오른쪽 손목에 배치된 센서로부터 신체 신호와 활력징후(회전율, 가속, 자기장 방향)가 기록
  - 모든 활동은 50Hz의 샘플링 속도를 사용하여 기록
2. UTD-MHAD
  - 해상도 320x240px인 15비트 깊이와 샘플링 속도가 50Hz인 저비용 무선 관성 데이터 센서를 결합하여 만든 인간의 행동 데이터 세트
  - 8명의 피험자로부터 웨어러블 센서를 사용하여 27개의 작용을 기록. (1~21은 관성센서로 피험자의 오른쪽 손목에, 22~27은 경우 센서로 피험자의 오른쪽 대퇴부에 부착)
3. USC-HAD
  - 14개의 분야에서 12개의 일상활동과 관련된 데이터
  - 피험자의 오른쪽 힙에 모션노드를 부착하여 데이터를 수집
  - 피험자에게 자신만의 스타일로 활동하도록 요청 (ex. 계단 오르기, 앞으로 걷기)
  - 최대 샘플링 속도는 100Hz로 유지
4. WHARF
  - 피험자의 손목에 단일 3축 가속도계를 부착하여 기록
  - 17명의 피험자로부터 14개의 활동에 대한 데이터를 수집 (ex. 양치질, 머리 빗기, 모유 먹이기)
  - 샘플링 속도가 30H인 1000개 이상의 기록으로 구성
5. WISDM
  - 휴대폰의 가속도계에서 생성된 시계열 데이터 모음
  - 일상활동을 하는 동안 피험자의 허리에 장치를 설치
  - 20Hz의 샘플링 속도로 109827개 수집

### **2. 샘플 생성 과정**
1. 서로 다른 센서의 원시 시계열에서 샘플을 생성 : 고정된 크기의 일시적인 창을 사용하여 전체 시계열을 동일한 부분을 나눔 (마지막 데이터 표본의 길이가 다른 데이터 표본과 같지 않은 경우는 제외)  

  - 데이터 분할을 위한 일시적인 창을 사용하는 방법
    1. SNOW
        - 입력 데이터 시퀀스에 고정크기의 창을 적용하여 train/test 샘플을 위한 데이터를 생성
        - 반은 겹치지 않음
        - 후속 창 간에 50$의 중복이 있기 때문에 매우 편향적  
    2. FNOW
        - 후속 창간에 겹침이 발생하지 않음 → 대규모 데이터 샘플(딥러닝 모델에 대한 필수 요건)을 충족하지 못하는 적은 수의 데이터 샘플 생성   
        
2. FNOW에 데이터의 편향을 유지하면서 표본 크기를 늘리기 위해 LOTO(Leave One Trial Out)을 제안  
  (데이터 분할 중에 한 데이터 그룹의 신호가 10-교차검증 중에 다른 그룹과 혼합되어서는 안됨)
3. 반 겹침 창(SNOW)을 사용하여 데이터 샘플을 생성  

### **3. 평가 프로토콜**
![accuracy](https://user-images.githubusercontent.com/59431387/103484648-d7750080-4e33-11eb-9b19-81146180f083.png)
1. accuracy
  - 전체 표본 수에 대한 정확한 예측 표본의 비율
  - 데이터가 균형이 잡혀있는 경우, 분류 성능을 측정하는데 권장되는 메트릭
2. recall
3. F1-score
  - accuracy와 recall의 가중 평균
  - 데이터가 불균형한 경우에 사용  
  
<br/></br>
## **4. 결과**
- 모든 실험은 NVIDIA P100 GPU에서 Tensorflow Keras를 사용하여 python에서 구현
- 더 나은 매개변수를 선택하기 위하여 1)하이퍼 파라미터를 조정   2)LOTO에서 생성된 샘플에 대해 5-교차검증 수행
- 변경사항  
    CNN layer 필터수 : {1,2,3,6,12}로 변경  
    LSTM layer 유닛수 : {8,16,32,64} -> {6,16,32,64}로 변경  
    Attention layer 출력길이 : {6,8,8,10,12,14}로 변경  
    학습속도 : {1,e-1,12,12,12}로 변경  
- 결과의 편향을 피하기 위하여 SNOW/FNOW 데이터셋에서 수행된 실험에 10-교차검증 수행
- CNN 필터 수 : 3, LSTM 유닛 수 : 32, LSTM 레이어 수 : 1, attentino 길이 : 32, attention layer 출력길이 : 10, batch size : 32, 학습속도 : 1e-4로 설정 (MHEACH의 경우, CNN 필터 수 : 6으로 설정)
- CNN필터 크기는 관련 데이터의 일시적인 창의 크기와 동일하게 설정
- validation loss를 모니터링

### **1. 검체 생성의 효과**  
[다양한 샘플 생성을 이용한 접근법별 성능]  
![snow_fnow_loto](https://user-images.githubusercontent.com/59431387/103484741-84e81400-4e34-11eb-8bfe-799f27cad4dd.PNG)  

- SNOW에서 생성된 샘플의 경우 평균 정확도가 상당히 높음 → 데이터 생성 중에 이후 샘플에서 50%의 중복이 발생하고 일부 훈련 데이터 샘플이 혼합될 가능성이 높기 때문
- FNOW를 사용해 생성된 샘플도 평균 정확도가 높음 → 데이터 생성 중 후속 샘플 간에는 중복이 없지만 동일한 피험자의 훈련데이터에서 얻은 데이터 샘플이 시험샘플에 거의 없을 가능성이 높음
- LOTO의 경우 WISDM데이터 세트의 평균 정확도가 크게 떨어짐  

SNOW에 비해 LOTO에서 낮은 결과가 나타났다. 그러나 가장 복잡한 데이터인 UTD-MHAD1과 WARF에 대해 LOTO를 사용하여 평균 정확도가 많이 향상되었다. 결론적으로 LOTO는 bias없이 좋은 결과를 얻었다.  

### **2. 기준과 비교**
기존 접근 방식인 ConvLSTM에 대해 제안된 접근 방식을 테스트 하였다. 제안도니 네트워크에 자기주의 메커니즘을 포함시키는 것의 중요성을 강조하고 싶기 때문이다.  
ConvLSTM의 경우, LSTM 장치 수 32개, LSTM레이어 수 1, CNN 필터 3, 학습률 0.001로 설정하였다. 초기 epoch를 100으로 설정하고 10이내로 유효성 손실에 대한 조기 중단을 도입하였다.  

[정확도를 사용한 기준 접근법(deep ConvLSTM)을 이용한 제안된 접근법 비교]
![f1](https://user-images.githubusercontent.com/59431387/103484739-831e5080-4e34-11eb-91d9-9c72a21cfd3f.PNG)  

데이터 세트는 본질적으로 불균형하기 때문에 분석 및 비교에 정확도가 불충분하므로 recall과 F1-score도 함께 사용하였다. 제안된 접근방식은 MHEACH와 WISDM을 제외한 모든 데이터 세트가 개선되었음을 보여준다. MHEACH와 WISDM의 경우 모두 분류 정확도가 이미 90%이상이기 때문에 큰 개선사항이 보이지 않았다.  
그래프 (a)와 (b)는 제안된 모델과 ConvLSTM모델을 사용하여 서로 다른 데이터 세트의 LOTO체계에서 얻은 정확도과 F1-score의 boxplot을 보여준다. 제안된 모델이 F1-score와 대부분의 경우 정확도 측면에서 기준 ConvLSTM모델보다 성능이 우수함을 알 수 있었다. 전반적으로 제안된 접근방식은 ConvLSTM에 비해 상당한 개선을 보여준다.

### **3. 기존 작업과의 비교분석**
기존의 최첨단 방법에 대해 새로운 접근 방식을 비교하였다. 새로운 방식을 기존의 기계학습에서 수작업으로 만든 특징을 사용하는 접근법과 비교하는 것이다. 하이퍼 파라미터, 데이터 세트 유형 및 데이터 생성 기법의 높은 변동성으로 인해 직접 비교할 수 없기 때문에 준비된 데이터 세트에 대해 모든 실험을 수행한다. 이는 원래작업과는 다르기 때문에 네트워크 아키텍처와 최적의 하이퍼미터도 다를 것이므로 실험에서 사용된 네트워크 아키텍처와 하이퍼 파라미터 설정을 한 다음 기존의 최첨단 접근법과 비교한다.  

[기존 연구와 접근된 제안의 비교]
![t3](https://user-images.githubusercontent.com/59431387/103485999-efea1880-4e3d-11eb-989b-8d2341bbc3fa.PNG)  

정확성 면에서 새로운 접근 방식은 기존 문헌에서 발견되는 모든 방법보다 우수하다. 
